# Machine Learning Lecture

This repository contains the materials for the lecture on Machine Learning at Clermont (November 2017), done by Andrey Ustyuzhanin (from Yandex). This lecture is organized in three days and cover the items below. For each part, there is example notebook to play with the described algorithms, implemented in scikit-learn or tensorflow. The data is describing flight delays.


### Day 1: Basics

- After a general introduction about the scope of ML and some definitions, few linear models were described (linear regression/classification, logistic regression, nearest neighbours). Then the general method de estimate the quality of an algorithm is given (definition of figure of merit). The notion of regularization is introduced together with few examples. The principle of a decision tree is then detailed. A way to pre-process categorical feature is also discussed and tried.


### Day 2: Optimization

- The first part of the lecture is about ensemble-based methods (_i.e._ combine several week algorithm into one). This approach, also called boosting, includes different type of algorithms (naive boosting, adaptative boosting, gradient boosting) which are detailed.
   
- The second part of this lecture is about hyperparameter tuning (_i.e._ how to tune the free parameters of an algorithm to get the best possible result). The notion de bayesian optimization with its acquisition function is introduced and the example of gaussian process is given to explain how to deal with a surrogate (ansatz function).


### Day 3: Introduction to TensorFlow

- A brief introduction to neural network is given with an overview of convolutional neural network. Then the library TensorFlow is introduced and used in the practical session.

